name: ppo

algo: # algo params 
  learning_rate_pi: 1e-5
  learning_rate_vf: 1e-4
  gamma: 0.99
  steps_per_epoch: 4000
  clip_ratio: 0.2
  train_pi_iters: 80
  train_vf_iters: 80
  lam: 0.97
  target_kl: 0.01
  max_kl_ratio: 1.5
  use_random_action_noise: True
  random_action_noise_size: 0.2
  optimiser: "adam" # adam/adamW/RMSProp
  use_kl_penalty: False
  use_entropy_regularisation: False
  kl_penalty_coefficient: 0.2
  entropy_coefficient:  1e-4
  adam_beta1: 0.9
  adam_beta2: 0.999
  grad_clamp_value: null
  rngseed: 123

trainer: # trainer params
  num_episodes: 1000
  test_freq: 200
  save_freq: 200
  use_curriculum: False
  rngseed: 123
  log_level: 1
  plot: false
  render: false