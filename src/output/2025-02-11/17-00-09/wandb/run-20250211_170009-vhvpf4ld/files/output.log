[2025-02-11 17:00:11,258][root][INFO] - {'model': {'name': 'ppo', 'algo': {'learning_rate_pi': 1e-05, 'learning_rate_vf': 0.0001, 'gamma': 0.99, 'steps_per_epoch': 4000, 'clip_ratio': 0.2, 'train_pi_iters': 80, 'train_vf_iters': 80, 'lam': 0.97, 'target_kl': 0.01, 'max_kl_ratio': 1.5, 'use_random_action_noise': True, 'random_action_noise_size': 0.2, 'optimiser': 'adam', 'use_kl_penalty': False, 'use_entropy_regularisation': False, 'kl_penalty_coefficient': 0.2, 'entropy_coefficient': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'grad_clamp_value': None, 'rngseed': 123}, 'trainer': {'num_episodes': 1000, 'test_freq': 200, 'save_freq': 200, 'use_curriculum': False, 'rngseed': 123, 'log_level': 1, 'plot': False, 'render': False}}, 'env': {'name': 'Pendulum-v1', 'seed': 123}, 'wandb': {'project': 'motion-predictor', 'job_type': 'train', 'name': 'name-me ${now:%Y_%m_%d_%H_%M_%S}', 'mode': 'online'}, 'device': 'cuda'}
Trainer settings:
 -> Run name: run_17-00
 -> Group name: 2025-02-11
 -> Given seed: 123
 -> Training reproducible: False
 -> Using device: cpu
 -> Save enabled: True
 -> Save path: models/2025-02-11/
Saving file models/2025-02-11/run_17-00/Trainer_params_001.lz4 with pickle ... finished
Saving file models/2025-02-11/run_17-00/Tracking_info.lz4 with pickle ... finished
Saving file models/2025-02-11/run_17-00/Agent_PPO_001.lz4 with pickle ... finished
Trainer hyperparameters:

{'num_episodes': 1000
 'test_freq': 200
 'save_freq': 200
 'use_curriculum': False
 'rngseed': 123
 'training_reproducible': False
 'saving_enabled': True}

Agent hyperparameters:

{'learning_rate_pi': 1e-05
 'learning_rate_vf': 0.0001
 'gamma': 0.99
 'steps_per_epoch': 4000
 'clip_ratio': 0.2
 'train_pi_iters': 80
 'train_vf_iters': 80
 'lam': 0.97
 'target_kl': 0.01
 'max_kl_ratio': 1.5
 'use_random_action_noise': True
 'random_action_noise_size': 0.2
 'optimiser': 'adam'
 'use_kl_penalty': False
 'use_entropy_regularisation': False
 'kl_penalty_coefficient': 0.2
 'entropy_coefficient': 0.0001
 'adam_beta1': 0.9
 'adam_beta2': 0.999
 'grad_clamp_value': None
 'network_name': 'MLPActorCriticPG_128x128'}

Env hyperparameters:

{'act_dim': 1
 'obs_dim': 3
 'env_type': 'gym env'}


Saving file models/2025-02-11/run_17-00/hyperparameters_001.lz4 with pickle ... finished

Begin training, target is 1000 episodes

Begin training episode 1
Episode 10 training metrics:
 -> duration = 200.000
 -> reward = -1473.805

Begin training episode 11
Episode 20 training metrics:
 -> duration = 200.000
 -> reward = -1824.798

Begin training episode 21
Episode 30 training metrics:
 -> duration = 200.000
 -> reward = -1205.225

Begin training episode 31
Traceback (most recent call last):
  File "/workspace/src/launch_training.py", line 58, in main
    trainer.train()
  File "/workspace/src/trainers/base_trainer.py", line 747, in train
    self.run_episode(i_episode)
  File "/workspace/src/trainers/base_trainer.py", line 669, in run_episode
    self.agent.update_step(obs, action, new_obs, reward, done, truncated)
  File "/workspace/src/agents/policy_gradient.py", line 1004, in update_step
    self.optimise_model()
  File "/workspace/src/agents/policy_gradient.py", line 933, in optimise_model
    loss_pi, pi_info = self.compute_loss_pi(data)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/src/agents/policy_gradient.py", line 891, in compute_loss_pi
    pi, logp = self.mlp_ac.pi(obs, act)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/src/agents/policy_gradient.py", line 174, in forward
    pi = self._distribution(obs)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/src/agents/policy_gradient.py", line 213, in _distribution
    return Normal(mu, std)
           ^^^^^^^^^^^^^^^
  File "/.venv/lib/python3.11/site-packages/torch/distributions/normal.py", line 59, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/.venv/lib/python3.11/site-packages/torch/distributions/distribution.py", line 71, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (4000, 1)) of distribution Normal(loc: torch.Size([4000, 1]), scale: torch.Size([4000, 1])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan],
        [nan],
        [nan],
        ...,
        [nan],
        [nan],
        [nan]], grad_fn=<AddmmBackward0>)
